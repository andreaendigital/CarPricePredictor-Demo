# ğŸš€ Car Price Prediction Platform - Enterprise DevOps Documentation for Expo

## Executive Summary

**Professional full-stack machine learning platform** for automotive price prediction with enterprise-grade DevOps architecture, comprehensive observability, and modern cloud deployment strategies.

### Business Value
- **Real-time ML Predictions** - Instant vehicle valuations using XGBoost algorithms
- **Enterprise Observability** - 1,070+ metrics per hour with Splunk Observability Cloud
- **Infrastructure as Code** - Complete AWS deployment automation
- **Production-Ready** - High availability, auto-scaling, and comprehensive monitoring

---

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "GitHub Repositories"
        A[tf-infra-demoCar<br/>Infrastructure Code]
        B[configManagement-carPrice<br/>Ansible Configuration]
        C[CarPricePredictor-Demo<br/>Flask Application]
    end

    subgraph "Jenkins CI/CD"
        D[Jenkinsfile<br/>Pipeline Orchestration]
    end

    subgraph "AWS Infrastructure"
        E[VPC + Subnets<br/>Network Layer]
        F[EC2 Instance<br/>Application Server]
        I[S3 Bucket<br/>Terraform State]
    end

    subgraph "Monitoring Stack"
        J[Splunk Observability<br/>Metrics & Dashboards]
        K[OpenTelemetry<br/>Collector]
    end

    A --> D
    B --> D
    D --> E
    D --> F
    D --> I
    C --> F
    F --> K
    K --> J
```

### Repository Architecture

**Infrastructure Repository**: tf-infra-demoCar
```
tf-infra-demoCar/
â”œâ”€â”€ Jenkinsfile                    # CI/CD Pipeline Definition
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ main.tf                   # Main Infrastructure Configuration
â”‚   â”œâ”€â”€ variables.tf              # Input Variables
â”‚   â”œâ”€â”€ outputs.tf                # Output Values
â”‚   â”œâ”€â”€ terraform.tfvars          # Variable Values
â”‚   â”œâ”€â”€ monitoring.tf             # Observability Integration
â”‚   â”œâ”€â”€ remote_backend_s3.tf      # Remote State Configuration
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ networking/           # VPC, Subnets, Routing
â”‚       â”œâ”€â”€ security-groups/      # Security Group Rules
â”‚       â”œâ”€â”€ ec2/                  # EC2 Instance Configuration

â”‚       â””â”€â”€ s3/                   # S3 Bucket for State
â””â”€â”€ README.md                     # Infrastructure Documentation
```

**Configuration Management Repository**: configManagement-carPrice
```
configManagement-carPrice/
â”œâ”€â”€ playbook.yml                  # Main Ansible Playbook
â”œâ”€â”€ generate_inventory.sh         # Dynamic Inventory Generator
â”œâ”€â”€ inventory.ini                 # Ansible Inventory File
â””â”€â”€ roles/
    â”œâ”€â”€ flask_app/               # Flask Application Role
    â”‚   â”œâ”€â”€ defaults/main.yml    # Default variables
    â”‚   â”œâ”€â”€ tasks/main.yml       # Application deployment tasks
    â”‚   â””â”€â”€ templates/
    â”‚       â”œâ”€â”€ app.service.j2   # Backend systemd service
    â”‚       â”œâ”€â”€ frontend.service.j2 # Frontend systemd service
    â”‚       â””â”€â”€ start-production.sh.j2 # Production startup script
    â””â”€â”€ splunk_monitoring/       # Monitoring Role
        â”œâ”€â”€ tasks/main.yml       # OpenTelemetry installation
        â”œâ”€â”€ templates/
        â”‚   â””â”€â”€ agent_config.yaml.j2 # OTel Collector config
        â”œâ”€â”€ handlers/main.yml    # Service restart handlers
        â””â”€â”€ vars/main.yml        # Configuration variables
```

---

## ğŸ”„ Deployment Flow Architecture

### Complete Pipeline Flow

```mermaid
flowchart TD
    A[ğŸš€ Jenkins Pipeline Start] --> B[ğŸ“¥ Clone Repositories]
    B --> C[tf-infra-demoCar]
    B --> D[configManagement-carPrice]

    C --> E[ğŸ—ï¸ Terraform Init]
    E --> F[ğŸ“‹ Terraform Plan]
    F --> G[ğŸš€ Terraform Apply]

    G --> H[ğŸŒ AWS Infrastructure]
    H --> I[VPC + Subnets<br/>10.0.0.0/16]
    H --> J[ğŸ”’ Security Groups<br/>SSH, HTTP, App Ports]
    H --> K[ğŸ’» EC2 Instance<br/>t3.small Amazon Linux]
    H --> L[ğŸ“¦ S3 Bucket<br/>Terraform State]

    D --> M[ğŸ“ Generate Inventory]
    M --> N[ğŸ”§ Ansible Deployment]

    N --> O[ğŸ Flask App Role]
    N --> P[ğŸ“Š Monitoring Role]

    O --> Q[System Updates]
    O --> R[Python Setup]
    O --> S[App Deployment]
    O --> T[Service Creation]

    P --> U[OpenTelemetry Install]
    P --> V[Metrics Configuration]
    P --> W[Splunk Integration]

    T --> X[ğŸ¯ Health Checks]
    W --> X
    X --> Y[âœ… Production Ready]

    style A fill:#e1f5fe
    style Y fill:#c8e6c9
    style H fill:#fff3e0
```



---

## ğŸ“Š Enterprise Observability Framework

### Telemetry Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SPLUNK OBSERVABILITY CLOUD                  â”‚
â”‚                     Enterprise Monitoring Platform              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚ Metrics & Telemetry
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
            â”‚ Application  â”‚ â”‚Infrastructureâ”‚ â”‚ Pipeline  â”‚
            â”‚   Layer      â”‚ â”‚   Layer      â”‚ â”‚  Layer    â”‚
            â”‚              â”‚ â”‚              â”‚ â”‚           â”‚
            â”‚ â€¢ Backend    â”‚ â”‚ â€¢ EC2 Metricsâ”‚ â”‚ â€¢ Jenkins â”‚
            â”‚ â€¢ Frontend   â”‚ â”‚ â€¢ CPU/Memory â”‚ â”‚ â€¢ Terraformâ”‚
            â”‚ â€¢ ML Models  â”‚ â”‚ â€¢ Network    â”‚ â”‚ â€¢ Ansible â”‚
            â”‚ â€¢ Business   â”‚ â”‚ â€¢ Disk Usage â”‚ â”‚ â€¢ Health  â”‚
            â”‚   KPIs       â”‚ â”‚ â€¢ System     â”‚ â”‚   Checks  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
            â”‚ OpenTelemetryâ”‚ â”‚HostMetrics  â”‚ â”‚ Jenkins   â”‚
            â”‚ Collector    â”‚ â”‚ Collector   â”‚ â”‚ Pipeline  â”‚
            â”‚ (Port 3000)  â”‚ â”‚ (10s int.)  â”‚ â”‚ Metrics   â”‚
            â”‚ (Port 5002)  â”‚ â”‚             â”‚ â”‚           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Collection Flow

```mermaid
flowchart LR
    subgraph "Data Sources"
        A[ğŸ–¥ï¸ Backend App<br/>~360/hour<br/>30s interval]
        B[ğŸŒ Frontend App<br/>~360/hour<br/>30s interval]
        C[ğŸ—ï¸ EC2 Infrastructure<br/>~200/hour<br/>10s interval]
        D[ğŸ”§ Jenkins Pipeline<br/>~50/deployment]
        E[â˜ï¸ AWS Resources<br/>~100/hour<br/>60s interval]
    end

    subgraph "Collection Layer"
        F[ğŸ“Š OpenTelemetry<br/>Collector]
        G[ğŸ“ˆ HostMetrics<br/>Collector]
        H[ğŸ”„ Pipeline<br/>Metrics]
    end

    subgraph "Processing"
        I[ğŸ”„ Resource Detection]
        J[ğŸ·ï¸ Attribute Processing]
        K[ğŸ“¤ Splunk Export]
    end

    A --> F
    B --> F
    C --> G
    D --> H
    E --> G

    F --> I
    G --> I
    H --> I

    I --> J
    J --> K

    K --> L[â˜ï¸ Splunk Observability<br/>~1,070 metrics/hour]

    style L fill:#e1f5fe
```



### Monitoring Metrics Available

#### **Backend Metrics**
- `car_price.system.cpu_percent` - System CPU usage
- `car_price.system.memory_percent` - Memory utilization
- `car_price.system.disk_usage` - Disk usage percentage
- `car_price.app.uptime_seconds` - Application uptime
- `car_price.app.total_requests` - Total API requests
- `car_price.app.total_predictions` - ML predictions made
- `car_price.business.avg_prediction_value` - Average car price predicted
- `car_price.business.model_accuracy` - ML model accuracy
- `car_price.business.active_users` - Active user count

#### **Frontend Metrics**
- `car_price.frontend.cpu_percent` - Frontend CPU usage
- `car_price.frontend.memory_percent` - Frontend memory usage
- `car_price.frontend.uptime_seconds` - Frontend uptime
- `car_price.frontend.total_requests` - Web requests
- `car_price.frontend.prediction_requests` - Prediction requests
- `car_price.frontend.publish_requests` - Vehicle publish requests
- `car_price.frontend.page_load_time` - Page load performance

#### **DevOps Pipeline Metrics**
- `jenkins.pipeline.success/failure` - Pipeline results
- `jenkins.terraform.apply.duration` - Infrastructure deployment time
- `jenkins.ansible.deploy.duration` - Configuration deployment time
- `terraform.ec2.deployment` - Infrastructure changes
- `ansible.deployment.success` - Configuration success

---

## ğŸ”§ Jenkins Pipeline Implementation

### Pipeline Execution Flow

```mermaid
flowchart TD
    A[ğŸš€ Pipeline Start] --> B[ğŸ“¥ Checkout Stage]
    B --> C[ğŸ“Š Send Checkout Metric]

    C --> D[ğŸ—ï¸ Terraform Plan]
    D --> E[â±ï¸ Measure Duration]
    E --> F[ğŸ“Š Send Plan Metric]

    F --> G[ğŸš€ Terraform Apply]
    G --> H[â±ï¸ Measure Duration]
    H --> I[ğŸ“Š Send Apply Metric]

    I --> J[ğŸ”§ Ansible Deploy]
    J --> K[â±ï¸ Measure Duration]
    K --> L[ğŸ“Š Send Deploy Metric]

    L --> M[ğŸ¯ Health Check]
    M --> N[ğŸ” Backend Health]
    M --> O[ğŸ” Frontend Health]

    N --> P[ğŸ“Š Send Health Metrics]
    O --> P

    P --> Q{âœ… Success?}
    Q -->|Yes| R[ğŸ“Š Success Metric]
    Q -->|No| S[âŒ Failure Metric]

    R --> T[â˜ï¸ Splunk Observability]
    S --> T

    style A fill:#e1f5fe
    style T fill:#e8f5e8
    style Q fill:#fff3e0
```

### Jenkins Pipeline with Splunk Metrics

```groovy
pipeline {
    agent any

    environment {
        SPLUNK_TOKEN = 'PZuf3J0L2Op_Qj9hpAJzlw'
        SPLUNK_REALM = 'us1'
        SPLUNK_URL = "https://ingest.${SPLUNK_REALM}.signalfx.com/v2/datapoint"
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
                script {
                    sendSplunkMetric('jenkins.stage.checkout', 1, [
                        stage: 'checkout',
                        job: env.JOB_NAME,
                        build: env.BUILD_NUMBER
                    ])
                }
            }
        }

        stage('Terraform Plan') {
            steps {
                script {
                    def startTime = System.currentTimeMillis()

                    sh '''
                        cd terraform
                        terraform init
                        terraform plan -out=tfplan
                    '''

                    def duration = (System.currentTimeMillis() - startTime) / 1000
                    sendSplunkMetric('jenkins.terraform.plan.duration', duration, [
                        stage: 'terraform-plan',
                        job: env.JOB_NAME
                    ])
                }
            }
        }

        stage('Terraform Apply') {
            steps {
                script {
                    def startTime = System.currentTimeMillis()

                    sh '''
                        cd terraform
                        terraform apply -auto-approve tfplan
                    '''

                    def duration = (System.currentTimeMillis() - startTime) / 1000
                    sendSplunkMetric('jenkins.terraform.apply.duration', duration, [
                        stage: 'terraform-apply',
                        job: env.JOB_NAME
                    ])
                }
            }
        }

        stage('Ansible Deploy') {
            steps {
                script {
                    def startTime = System.currentTimeMillis()

                    sh '''
                        cd ansible
                        ansible-playbook -i inventory splunk-observability.yml
                        ansible-playbook -i inventory deploy-app.yml
                    '''

                    def duration = (System.currentTimeMillis() - startTime) / 1000
                    sendSplunkMetric('jenkins.ansible.deploy.duration', duration, [
                        stage: 'ansible-deploy',
                        job: env.JOB_NAME
                    ])
                }
            }
        }

        stage('Health Check') {
            steps {
                script {
                    def ec2Ip = sh(
                        script: 'cd terraform && terraform output -raw ec2_public_ip',
                        returnStdout: true
                    ).trim()

                    // Check backend health
                    def backendHealth = sh(
                        script: "curl -f http://${ec2Ip}:5002/health",
                        returnStatus: true
                    )

                    // Check frontend health
                    def frontendHealth = sh(
                        script: "curl -f http://${ec2Ip}:3000/health",
                        returnStatus: true
                    )

                    sendSplunkMetric('jenkins.health.backend', backendHealth == 0 ? 1 : 0, [
                        service: 'backend',
                        ec2_ip: ec2Ip
                    ])

                    sendSplunkMetric('jenkins.health.frontend', frontendHealth == 0 ? 1 : 0, [
                        service: 'frontend',
                        ec2_ip: ec2Ip
                    ])
                }
            }
        }
    }

    post {
        success {
            script {
                sendSplunkMetric('jenkins.pipeline.success', 1, [
                    job: env.JOB_NAME,
                    build: env.BUILD_NUMBER,
                    result: 'success'
                ])
            }
        }
        failure {
            script {
                sendSplunkMetric('jenkins.pipeline.failure', 1, [
                    job: env.JOB_NAME,
                    build: env.BUILD_NUMBER,
                    result: 'failure'
                ])
            }
        }
    }
}

def sendSplunkMetric(metricName, value, dimensions) {
    def payload = [
        gauge: [[
            metric: metricName,
            value: value,
            dimensions: dimensions + [
                timestamp: System.currentTimeMillis(),
                jenkins_url: env.JENKINS_URL,
                node_name: env.NODE_NAME
            ]
        ]]
    ]

    sh """
        curl -X POST ${SPLUNK_URL} \
        -H "X-SF-Token: ${SPLUNK_TOKEN}" \
        -H "Content-Type: application/json" \
        -d '${groovy.json.JsonBuilder(payload).toString()}'
    """
}
```

---



---

## ğŸ“Š Available Dashboards

### Dashboard Architecture

```mermaid
flowchart LR
    subgraph "Local Dashboards"
        A[ğŸ–¥ï¸ Backend Dashboard<br/>Port 5002/dashboard<br/>â€¢ System Metrics<br/>â€¢ API Performance<br/>â€¢ 5s Auto-refresh]
        B[ğŸŒ Frontend Dashboard<br/>Port 3000/dashboard<br/>â€¢ Web Metrics<br/>â€¢ User Activity<br/>â€¢ Health Status]
    end

    subgraph "Enterprise Platform"
        C[â˜ï¸ Splunk Observability<br/>app.us1.signalfx.com<br/>â€¢ 1,070+ metrics/hour<br/>â€¢ Real-time streaming<br/>â€¢ 30-day retention<br/>â€¢ Custom dashboards]
    end

    subgraph "Data Flow"
        D[ğŸ“Š Metrics Collection]
        E[ğŸ”„ Real-time Processing]
        F[ğŸ“ˆ Visualization]
    end

    A --> D
    B --> D
    D --> E
    E --> F
    F --> C

    style C fill:#e1f5fe
    style A fill:#fff3e0
    style B fill:#f3e5f5
```

### **Backend Dashboard** (Port 5002/dashboard)
- **System Metrics**: CPU, Memory, Uptime
- **API Performance**: Total requests, ML predictions
- **Real-time Updates**: Auto-refresh every 5 seconds
- **Splunk Integration**: Direct link to observability platform

### **Frontend Dashboard** (Port 3000/dashboard)
- **Web Metrics**: User requests, predictions, publishes
- **System Performance**: CPU, Memory usage
- **User Activity**: Real-time interaction tracking
- **Health Status**: Service connectivity monitoring

### **Splunk Observability Cloud**
- **Comprehensive Metrics**: 1,070+ metrics/hour
- **Real-time Visualization**: Live data streaming
- **Historical Analysis**: 30-day data retention
- **Custom Dashboards**: Business and technical KPIs

---

## ğŸš€ Implemented Metrics

### **Backend Metrics (Actually Implemented)**

```python
# System Performance Metrics
car_price.system.cpu_percent        # Real-time CPU usage
car_price.system.memory_percent     # Real-time memory usage
car_price.system.disk_usage         # Disk usage percentage

# Application Metrics
car_price.app.uptime_seconds        # Application uptime
car_price.app.total_requests        # Total API requests
car_price.app.total_predictions     # ML predictions made

# Business KPIs (Simulated)
car_price.business.avg_prediction_value  # Average car price predicted
car_price.business.model_accuracy        # ML model accuracy (simulated)
car_price.business.active_users          # Active user count (simulated)

# Prediction Tracking
car_price.predictions.current_value      # Current price predictions
car_price.predictions.future_value       # Future price predictions
car_price.business.months_forecast       # Forecast months requested
car_price.requests.total                 # Total requests counter
```

### **Frontend Metrics (Actually Implemented)**

```python
# System Performance Metrics
car_price.frontend.cpu_percent           # Frontend CPU usage
car_price.frontend.memory_percent        # Frontend memory usage

# Application Metrics
car_price.frontend.uptime_seconds        # Frontend uptime
car_price.frontend.total_requests        # Total web requests
car_price.frontend.prediction_requests   # Prediction requests
car_price.frontend.publish_requests      # Vehicle publish requests

# User Experience Metrics
car_price.frontend.page_load_time        # Page load performance (simulated)
car_price.frontend.predictions           # User prediction actions
car_price.frontend.publishes             # User publish actions
car_price.frontend.requests.total        # Frontend request counter
car_price.frontend.publish.total         # Publish counter
```

### Real-time Monitoring Flow

```mermaid
flowchart TD
    subgraph "User Interactions"
        A[ğŸ‘¤ User Prediction Request]
        B[ğŸ“ Vehicle Publish Action]
        C[ğŸ” Dashboard Access]
    end

    subgraph "Application Layer"
        D[ğŸ–¥ï¸ Backend Service<br/>Port 5002]
        E[ğŸŒ Frontend Service<br/>Port 3000]
    end

    subgraph "Metrics Generation"
        F[ğŸ“Š System Metrics<br/>CPU, Memory, Disk]
        G[ğŸ”¢ Business KPIs<br/>Predictions, Accuracy]
        H[âš¡ Event Metrics<br/>User Actions]
    end

    subgraph "Real-time Processing"
        I[ğŸ“ˆ 10s Continuous Collection]
        J[ğŸ¯ Event-driven Collection]
        K[ğŸ’“ Health Monitoring]
    end

    A --> D
    B --> E
    C --> E

    D --> F
    D --> G
    E --> F
    E --> H

    F --> I
    G --> J
    H --> J

    I --> L[ğŸ“Š Live Dashboards]
    J --> L
    K --> L

    L --> M[â˜ï¸ Splunk Observability]

    style M fill:#e1f5fe
    style L fill:#f3e5f5
```



---

## ğŸ”§ Deployment Commands

### **Infrastructure Deployment**
```bash
# 1. Deploy infrastructure
cd terraform
terraform init
terraform plan
terraform apply

# 2. Configure monitoring
cd ../ansible
ansible-playbook -i inventory splunk-observability.yml

# 3. Deploy application
ansible-playbook -i inventory deploy-app.yml

# 4. Verify monitoring
curl http://13.220.64.167:5002/health
curl http://13.220.64.167:3000/health
```

### **Access Points**
- **Splunk Observability**: https://app.us1.signalfx.com
- **Production Application**: http://13.220.64.167:3000/
- **Backend Dashboard**: http://13.220.64.167:5002/dashboard
- **Frontend Dashboard**: http://13.220.64.167:3000/dashboard
- **Health Checks**: http://13.220.64.167:5002/health & http://13.220.64.167:3000/health

---

## Implementation Summary

**Platform Status**: Production-ready ML prediction service with enterprise DevOps architecture
**Monitoring Coverage**: Application, infrastructure, and pipeline metrics with Splunk Observability Cloud
**Architecture**: 3-repository structure with Terraform IaC, Ansible configuration, and Flask application
**Deployment**: Jenkins CI/CD pipeline with automated AWS provisioning and monitoring integration
**Team**: Jose Rubio (Project Lead) | Full-stack MLOps | SCRUM methodology

---

---

*Enterprise DevOps documentation for Car Price Prediction Platform - Complete AWS deployment with comprehensive observability and monitoring.*
